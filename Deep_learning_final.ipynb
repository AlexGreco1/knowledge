{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKyioeFAD+tmbLBxaD/+2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexGreco1/knowledge/blob/main/Deep_learning_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9cc808"
      },
      "source": [
        "# Deep Learning Example - Iris \n",
        "\n",
        "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7141cfab"
      },
      "source": [
        "#1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17aae7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5ede86-fc1d-4c9a-bb76-7702c9dbc1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "#Install related libraries for the course. \n",
        "#This is a common requirement for all other exampels too\n",
        "\n",
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#basic functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import re\n",
        "import warnings # Suppress warning for clean notebook\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Jxb2SUoZ-8fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def rename_features(data):\n",
        "  list_names_trans=[]\n",
        "\n",
        "  list_names=data.columns\n",
        "\n",
        "  for name in list_names:\n",
        "    list_names_trans.append(re.sub(\"\\s\", \"_\", name))\n",
        "\n",
        "  return list_names_trans\n",
        "\n",
        "\n",
        "def change_position_first(variable_position,data):\n",
        "  list_var=data.columns\n",
        "  first_column = data.pop(list_var[variable_position])\n",
        "  data.insert(0, list_var[variable_position], first_column)\n",
        "\n",
        "\n",
        "def split_x_y(data):\n",
        "\n",
        "    #after move the label data or y variable to the position 0 in the column arrange\n",
        "    #label encond the variable y\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    data.iloc[:,0] = label_encoder.fit_transform(data.iloc[:,0])\n",
        "\n",
        "    #Convert input to numpy array\n",
        "    X_data = data.iloc[:,1:].to_numpy()\n",
        "    Y_data = data.iloc[:,0].to_numpy()\n",
        "\n",
        "    #how many unique categories does it have\n",
        "    cat=data.iloc[:,0].nunique()\n",
        "    \n",
        "    #Separate feature and target variables\n",
        "    #X_data = np_iris_x[:,:]  #all rows,from column 0:4\n",
        "    #Y_data = np_iris_y[:,:]       #all rows,from column 4  \n",
        "    \n",
        "    #Create a scaler model that is fit on the input data.\n",
        "    scaler = StandardScaler().fit(X_data)\n",
        "    \n",
        "    #Scale the numeric feature variables\n",
        "    X_data = scaler.transform(X_data)\n",
        "\n",
        "\n",
        "    #Convert target variable as a one-hot-encoding array\n",
        "    Y_data = tf.keras.utils.to_categorical(Y_data,cat) # there are 3 categories\n",
        "\n",
        "    #print(\"X_data\")\n",
        "    #print(X_data)\n",
        "    #print(\"Y_data\")\n",
        "    #print(Y_data)\n",
        "\n",
        "    #Return Feature and Target variables\n",
        "    return X_data,Y_data\n",
        "\n",
        "\n",
        "def label_encoder_fun(dependen_variable_y,data):\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  data[dependen_variable_y] = label_encoder.fit_transform(data[dependen_variable_y])\n",
        "\n",
        "#def n_cat_y(variable_name,data):\n",
        "#  dep=variable_name\n",
        "#  cat=data[dep].nunique()\n",
        "#  return cat\n",
        "\n",
        "\n",
        "def data_exploring(data):\n",
        "  #explore dataset\n",
        "    print(f'data.shape {data.shape}')\n",
        "    print(f'data.nunique() {data.nunique()}')\n",
        "    print(f'data.isna().sum() {data.isna().sum()}')\n",
        "\n",
        "\n",
        "def fullfill_na_0(list_columns,data):\n",
        "    \n",
        "    # to fullfill with 0\n",
        "    #cols_to_fill_zero = ['Sepal.lengh','Sepal.width']\n",
        "    #cols_to_fill_zero=list_columns\n",
        "    data[list_columns] = data[list_columns].fillna(0)\n",
        "\n",
        "    #data.isna().sum()\n",
        "\n",
        "    #iris_data.rename(columns={'Petal_Length':'Petal.Length'})\n",
        "    # to fullfill with avg #check \n",
        "\n",
        "def fullfill_avg(column_name,data):\n",
        "    # to fullfill with 0\n",
        "    #cols_to_fill_zero = ['Sepal.lengh','Sepal.width']\n",
        "    #cols_to_fill_zero=list_columns\n",
        "    data[column_name] = data[column_name].fillna(data[column_name].mean())    \n",
        "    #iris_data['Petal.Length'] = iris_data['Petal.Length'].fillna(iris_data[['Petal.Length']].mean())\n",
        "    #iris_data['Petal.Length'] = iris_data['Petal.Length'].fillna(iris_data['Petal.Length'].mean())\n",
        "    #iris_data.isna().sum()\n",
        "\n",
        "def drop_null(data):\n",
        "    #drop null\n",
        "\n",
        "    data.dropna(inplace=True)\n",
        "    #iris_data.isna().sum()\n",
        "\n",
        "    \n",
        "    #Convert target variable as a one-hot-encoding array\n",
        "    #Y_data = tf.keras.utils.to_categorical(Y_data,3) # there is 3 categories\n",
        "\n",
        "\n",
        "def get_data(file_name,y_variable_position):\n",
        "    \n",
        "    data = pd.read_csv(file_name)\n",
        "    \n",
        "    rename_features(data)\n",
        "\n",
        "    change_position_first(y_variable_position,data)\n",
        "\n",
        "    data_exploring(data)\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#Function to create the default configuration for the model. This will be overridden as \n",
        "#required during experimentation\n",
        "#---------------------------------------------------------------------\n",
        "def base_model_config():\n",
        "    model_config = {\n",
        "            \"HIDDEN_NODES\" : [32,64],\n",
        "            \"HIDDEN_ACTIVATION\" : \"relu\",\n",
        "            \"OUTPUT_NODES\" : 3,\n",
        "            \"OUTPUT_ACTIVATION\" : \"softmax\",\n",
        "            \"WEIGHTS_INITIALIZER\" : \"random_normal\",\n",
        "            \"BIAS_INITIALIZER\" : \"zeros\",\n",
        "            \"NORMALIZATION\" : \"none\",\n",
        "            \"OPTIMIZER\" : \"rmsprop\",\n",
        "            \"LEARNING_RATE\" : 0.001,\n",
        "            \"REGULARIZER\" : None,\n",
        "            \"DROPOUT_RATE\" : 0.0,\n",
        "            \"EPOCHS\" : 10,\n",
        "            \"BATCH_SIZE\" : 16,\n",
        "            \"VALIDATION_SPLIT\" : 0.2,\n",
        "            \"VERBOSE\" : 0,\n",
        "            \"LOSS_FUNCTION\" : \"categorical_crossentropy\",\n",
        "            \"METRICS\" : [\"accuracy\"]\n",
        "            }\n",
        "    return model_config\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#Function to plot a graph based on the results derived\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "def plot_graph(accuracy_measures, title):\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for experiment in accuracy_measures.keys():\n",
        "        plt.plot(accuracy_measures[experiment], \n",
        "                 label=experiment,\n",
        "                    linewidth=3)\n",
        "        \n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "Ym6Y-1BxumWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "sQo2Z7CFK3cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test.\n",
        "\n",
        "iris_data = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "print(iris_data.head())\n",
        "\n",
        "change_position_first(4,iris_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iris_data.iloc[0,1]=np.nan\n",
        "\n",
        "drop_null(iris_data)\n",
        "\n",
        "print(iris_data.head())\n",
        "\n",
        "#print(iris_data.columns)\n",
        "\n",
        "#l=['Sepal.Length']\n",
        "\n",
        "#fullfill_na_0(l,iris_data)\n",
        "#fullfill_avg(l,iris_data)\n",
        "\n",
        "#iris_data.head()\n",
        "\n",
        "#label_encoder = preprocessing.LabelEncoder()\n",
        "#iris_data.iloc[:,0] = label_encoder.fit_transform(iris_data.iloc[:,0])\n",
        "\n",
        "#x,y=split_x_y(iris_data)\n",
        "\n",
        "\n",
        "\n",
        "#print(x)\n",
        "#print(y)\n",
        "#iris_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWO0t6tAZMe",
        "outputId": "5a7307fb-6591-4526-da5d-af22deff3b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "  Species  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
            "1  setosa           4.9          3.0           1.4          0.2\n",
            "2  setosa           4.7          3.2           1.3          0.2\n",
            "3  setosa           4.6          3.1           1.5          0.2\n",
            "4  setosa           5.0          3.6           1.4          0.2\n",
            "5  setosa           5.4          3.9           1.7          0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#basic functions\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#Function to read data and process. Get ready for Deep Learning\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "def rename_features(list_names):\n",
        "  list_names_trans=[]\n",
        "\n",
        "  for name in list_names:\n",
        "    list_names_trans.append(re.sub(\"\\s\", \"_\", name))\n",
        "\n",
        "  return list_names_trans\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    \n",
        "    iris_data = pd.read_csv(\"iris.csv\")\n",
        "    \n",
        "    #iris_data.dtypes\n",
        "    #iris_data.describe()\n",
        "    #iris_data.head()\n",
        "\n",
        "    \n",
        "    \n",
        "    #Use a Label encoder to convert String to numeric values for the target variable\n",
        "\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    #iris_data['Species'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "    dependen_variable_y = label_encoder.fit_transform(dependen_variable_y)\n",
        "\n",
        "    first_column = df.pop('e')\n",
        "    df.insert(0, 'e', first_column)\n",
        "    \n",
        "    #Convert input to numpy array\n",
        "    np_iris = iris_data.to_numpy()\n",
        "    \n",
        "    #Separate feature and target variables\n",
        "    X_data = np_iris[:,0:4].  #all rows,from column 0:4\n",
        "    Y_data=np_iris[:,4]       #all rows,from column 4  \n",
        "    \n",
        "    #Create a scaler model that is fit on the input data.\n",
        "    scaler = StandardScaler().fit(X_data)\n",
        "    \n",
        "    #Scale the numeric feature variables\n",
        "    X_data = scaler.transform(X_data)\n",
        "\n",
        "    #explore dataset\n",
        "    iris_data.nunique()\n",
        "    iris_data.shape\n",
        "    iris_data.isna().sum()\n",
        "\n",
        "    # to fullfill with 0\n",
        "    cols_to_fill_zero = ['Sepal.lengh','Sepal.width']\n",
        "    iris_data[cols_to_fill_zero] = iris_data[cols_to_fill_zero].fillna(0)\n",
        "\n",
        "    iris_data.isna().sum()\n",
        "\n",
        "    #iris_data.rename(columns={'Petal_Length':'Petal.Length'})\n",
        "    # to fullfill with avg #check \n",
        "    \n",
        "    iris_data['Petal.Length'] = iris_data['Petal.Length'].fillna(iris_data[['Petal.Length']].mean())\n",
        "    iris_data['Petal.Length'] = iris_data['Petal.Length'].fillna(iris_data['Petal.Length'].mean())\n",
        "    iris_data.isna().sum()\n",
        "\n",
        "    #drop null\n",
        "\n",
        "    iris_data.dropna(inplace=True)\n",
        "    iris_data.isna().sum()\n",
        "\n",
        "    \n",
        "    #Convert target variable as a one-hot-encoding array\n",
        "    Y_data = tf.keras.utils.to_categorical(Y_data,3) # there is 3 categories\n",
        "\n",
        "    #Return Feature and Target variables\n",
        "    return X_data,Y_data\n",
        "\n",
        "#explore and transform data:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#Function to create the default configuration for the model. This will be overridden as \n",
        "#required during experimentation\n",
        "#---------------------------------------------------------------------\n",
        "def base_model_config():\n",
        "    model_config = {\n",
        "            \"HIDDEN_NODES\" : [32,64],\n",
        "            \"HIDDEN_ACTIVATION\" : \"relu\",\n",
        "            \"OUTPUT_NODES\" : 3,\n",
        "            \"OUTPUT_ACTIVATION\" : \"softmax\",\n",
        "            \"WEIGHTS_INITIALIZER\" : \"random_normal\",\n",
        "            \"BIAS_INITIALIZER\" : \"zeros\",\n",
        "            \"NORMALIZATION\" : \"none\",\n",
        "            \"OPTIMIZER\" : \"rmsprop\",\n",
        "            \"LEARNING_RATE\" : 0.001,\n",
        "            \"REGULARIZER\" : None,\n",
        "            \"DROPOUT_RATE\" : 0.0,\n",
        "            \"EPOCHS\" : 10,\n",
        "            \"BATCH_SIZE\" : 16,\n",
        "            \"VALIDATION_SPLIT\" : 0.2,\n",
        "            \"VERBOSE\" : 0,\n",
        "            \"LOSS_FUNCTION\" : \"categorical_crossentropy\",\n",
        "            \"METRICS\" : [\"accuracy\"]\n",
        "            }\n",
        "    return model_config\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "# Function to create an optimizer based on the optimizer name and learning rate\n",
        "#---------------------------------------------------------------------\n",
        "def get_optimizer(optimizer_name, learning_rate):\n",
        "    #'sgd','rmsprop','adam','adagrad'\n",
        "    optimizer=None\n",
        "    \n",
        "    if optimizer_name == 'adagrad': \n",
        "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
        "\n",
        "    elif 'rmsprop':\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    elif'adam' :\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        \n",
        "    else :\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "            \n",
        "    return optimizer\n",
        "    \n",
        "    \n",
        "#---------------------------------------------------------------------\n",
        "# Function to create a model and fit the model\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "def create_and_run_model(model_config,X,Y,model_name) :\n",
        "    \n",
        "    model=tf.keras.models.Sequential(name=model_name)\n",
        "    \n",
        "    for layer in range(len(model_config[\"HIDDEN_NODES\"])):\n",
        "        \n",
        "        if (layer == 0):\n",
        "            model.add(\n",
        "                    keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
        "                    input_shape=(X.shape[1],),\n",
        "                    name=\"Dense-Layer-\" + str(layer),\n",
        "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
        "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
        "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
        "                    activation=model_config[\"HIDDEN_ACTIVATION\"]))\n",
        "        else:\n",
        "            \n",
        "            if ( model_config[\"NORMALIZATION\"] == \"batch\"):\n",
        "                model.add(keras.layers.BatchNormalization())\n",
        "                \n",
        "            if ( model_config[\"DROPOUT_RATE\"] > 0.0 ):\n",
        "                model.add(keras.layers.Dropout(model_config[\"DROPOUT_RATE\"]))\n",
        "                \n",
        "            model.add(\n",
        "                    keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
        "                    name=\"Dense-Layer-\" + str(layer),\n",
        "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
        "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
        "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
        "                    activation=model_config[\"HIDDEN_ACTIVATION\"])) \n",
        "            \n",
        "\n",
        "            \n",
        "    model.add(keras.layers.Dense(model_config[\"OUTPUT_NODES\"],\n",
        "                    name=\"Output-Layer\",\n",
        "                    activation=model_config[\"OUTPUT_ACTIVATION\"]))\n",
        "    \n",
        "    optimizer = get_optimizer( model_config[\"OPTIMIZER\"],\n",
        "                              model_config[\"LEARNING_RATE\"])\n",
        "    \n",
        "    model.compile(loss=model_config[\"LOSS_FUNCTION\"],\n",
        "                  optimizer=optimizer,\n",
        "                   metrics=model_config[\"METRICS\"])\n",
        "    \n",
        "    print(\"\\n******************************************************\")\n",
        "    model.summary()\n",
        "    \n",
        "    X_train, X_val, Y_train, Y_val =train_test_split(\n",
        "                        X,Y,\n",
        "                        stratify=Y,\n",
        "                        random_state=42,\n",
        "                        test_size=model_config[\"VALIDATION_SPLIT\"]) \n",
        "    \n",
        "    history=model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=model_config[\"BATCH_SIZE\"],\n",
        "          epochs=model_config[\"EPOCHS\"],\n",
        "          verbose=model_config[\"VERBOSE\"],\n",
        "          validation_data= (X_val, Y_val))\n",
        "    \n",
        "    return history\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#Function to plot a graph based on the results derived\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "def plot_graph(accuracy_measures, title):\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for experiment in accuracy_measures.keys():\n",
        "        plt.plot(accuracy_measures[experiment], \n",
        "                 label=experiment,\n",
        "                    linewidth=3)\n",
        "        \n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    "
      ],
      "metadata": {
        "id": "9rSWQWdYbbJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XrxMi1xwXY8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config[\"WEIGHTS_INITIALIZER\"],"
      ],
      "metadata": {
        "id": "ZRKHZoCfi1R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n-nCNcYli1OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QISFYx9Mi1LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now in a matrix.\n",
        "\n",
        "optimizations=[\"HIDDEN_NODES\",\n",
        "               \"NODES\",\n",
        "               \"BATCH_SIZE\",\n",
        "               \"EPOCHS\"\n",
        "               \"WEIGHTS_INITIALIZER\",\n",
        "               \"HIDDEN_ACTIVATION\",\n",
        "               \"OPTIMIZER\",\n",
        "               \"BATCH_NORMALIZATION\",\n",
        "               \"LEARNING_RATE\",\n",
        "               \"REGULARIZER\",\n",
        "               \"DROPOUT_RATE\"] \n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        " model_config = {\n",
        "            \"HIDDEN_NODES\" : [32,64],\n",
        "            \"HIDDEN_ACTIVATION\" : \"relu\",\n",
        "            \"OUTPUT_NODES\" : 3,\n",
        "            \"OUTPUT_ACTIVATION\" : \"softmax\",\n",
        "            \"WEIGHTS_INITIALIZER\" : \"random_normal\",\n",
        "            \"BIAS_INITIALIZER\" : \"zeros\",\n",
        "            \"NORMALIZATION\" : \"none\",\n",
        "            \"OPTIMIZER\" : \"rmsprop\",\n",
        "            \"LEARNING_RATE\" : 0.001,\n",
        "            \"REGULARIZER\" : None,\n",
        "            \"DROPOUT_RATE\" : 0.0,\n",
        "            \"EPOCHS\" : 10,\n",
        "            \"BATCH_SIZE\" : 16,\n",
        "            \"VALIDATION_SPLIT\" : 0.2,\n",
        "            \"VERBOSE\" : 0,\n",
        "            \"LOSS_FUNCTION\" : \"categorical_crossentropy\",\n",
        "            \"METRICS\" : [\"accuracy\"]\n",
        "            }"
      ],
      "metadata": {
        "id": "gMiXdXL9AcRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tuKiqq7xaS7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the big one\n",
        "\n",
        "initializer_list = ['random_normal','zeros','ones',\"random_uniform\"]\n",
        "normalization_list = ['none','batch']\n",
        "optimizer_list = ['sgd','rmsprop','adam','adagrad']\n",
        "learning_rate_list = [0.001, 0.005,0.01,0.1,0.5]\n",
        "regularizer_list = ['l1','l2','l1_l2']\n",
        "\n",
        "losses_list=[]\n",
        "\"\"\"Available losses\n",
        "Note that all losses are available both via a class handle and via a function handle. The class handles enable you to pass configuration arguments to the constructor (e.g. loss_fn = CategoricalCrossentropy(from_logits=True)), and they perform reduction by default when used in a standalone way (see details below).\n",
        "\n",
        "Probabilistic losses\n",
        "\n",
        "BinaryCrossentropy class\n",
        "CategoricalCrossentropy class\n",
        "SparseCategoricalCrossentropy class\n",
        "Poisson class\n",
        "binary_crossentropy function\n",
        "categorical_crossentropy function\n",
        "sparse_categorical_crossentropy function\n",
        "poisson function\n",
        "KLDivergence class\n",
        "kl_divergence function\n",
        "\n",
        "\n",
        "Regression losses\n",
        "\n",
        "MeanSquaredError class\n",
        "MeanAbsoluteError class\n",
        "MeanAbsolutePercentageError class\n",
        "MeanSquaredLogarithmicError class\n",
        "CosineSimilarity class\n",
        "mean_squared_error function\n",
        "mean_absolute_error function\n",
        "mean_absolute_percentage_error function\n",
        "mean_squared_logarithmic_error function\n",
        "cosine_similarity function\n",
        "Huber class\n",
        "huber function\n",
        "LogCosh class\n",
        "log_cosh function\n",
        "\n",
        "Hinge losses for \"maximum-margin\" classification\n",
        "\n",
        "Hinge class\n",
        "SquaredHinge class\n",
        "CategoricalHinge class\n",
        "hinge function\n",
        "squared_hinge function\n",
        "categorical_hinge function\n",
        "\"\"\"\n",
        "metrics_list=[]\n",
        "\"\"\"Available metrics\n",
        "\n",
        "Accuracy metrics\n",
        "\n",
        "Accuracy class\n",
        "BinaryAccuracy class\n",
        "CategoricalAccuracy class\n",
        "SparseCategoricalAccuracy class\n",
        "TopKCategoricalAccuracy class\n",
        "SparseTopKCategoricalAccuracy class\n",
        "\n",
        "Probabilistic metrics\n",
        "\n",
        "BinaryCrossentropy class\n",
        "CategoricalCrossentropy class\n",
        "SparseCategoricalCrossentropy class\n",
        "KLDivergence class\n",
        "Poisson class\n",
        "Regression metrics\n",
        "MeanSquaredError class\n",
        "RootMeanSquaredError class\n",
        "MeanAbsoluteError class\n",
        "MeanAbsolutePercentageError class\n",
        "MeanSquaredLogarithmicError class\n",
        "CosineSimilarity class\n",
        "LogCoshError class\n",
        "\n",
        "Classification metrics based on True/False positives & negatives\n",
        "\n",
        "AUC class\n",
        "Precision class\n",
        "Recall class\n",
        "TruePositives class\n",
        "TrueNegatives class\n",
        "FalsePositives class\n",
        "FalseNegatives class\n",
        "PrecisionAtRecall class\n",
        "SensitivityAtSpecificity class\n",
        "SpecificityAtSensitivity class\n",
        "\n",
        "Image segmentation metrics\n",
        "\n",
        "MeanIoU class\n",
        "Hinge metrics for \"maximum-margin\" classification\n",
        "Hinge class\n",
        "SquaredHinge class\n",
        "CategoricalHinge class\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Add the first hidden layer\n",
        "layer_0=\"model.add(keras.layers.Dense(\"128,\n",
        "first_layer={input_shape:(4,),\n",
        "             name:'Hidden-Layer-1',\n",
        "             activation:'relu'} \"   \n",
        "\n",
        "other_layer={input_shape:(4,),\n",
        "             name:'Hidden-Layer-1',\n",
        "             activation:'relu'} \"   \n",
        "\n",
        "\n",
        "                            #Add a second hidden layer\n",
        "                            model.add(keras.layers.Dense(128,\n",
        "                                                          name='Hidden-Layer-2',\n",
        "                                                          activation='relu'))\n",
        "\n",
        "                            #Add an output layer with softmax activation\n",
        "                            model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                                                        name='Output-Layer',\n",
        "                                                        activation='softmax'))\n",
        "\n",
        "for hidden_node_layers in range(1,20):\n",
        "  for node in range(1,200):\n",
        "    for activation_fucntions in activation_list:\n",
        "      for loss_fun in loss_list:\n",
        "        for batches in range(1,200)\n",
        "          for epochs in range(1,200):\n",
        "            for validation_split in range(0.05,0.5,0.01):\n",
        "              for WEIGHTS_INITIALIZER in initializer_list:\n",
        "                for BIAS_INITIALIZER in initializer_list: #not sure\n",
        "                  for NORMALIZATION in normalization_list:\n",
        "                    for OPTIMIZER in optimizer_list:\n",
        "                      for LEARNING_RATE in range(0.001,0.5,0.005):#this is too big but just to do it onces\n",
        "                        for REGULARIZER in regularizer_list:\n",
        "                          for DROPOUT_RATE in range(0.0,0.5,0.01):\n",
        "\n",
        "                            accuracy_measures = {}\n",
        "                            #layer_list =[]\n",
        "\n",
        "                            model = tf.keras.models.Sequential()\n",
        "\n",
        "                            #Add the first hidden layer\n",
        "                            model.add(keras.layers.Dense(128,                    #Number of nodes\n",
        "                                                        input_shape=(4,),       #Number of input variables\n",
        "                                                          name='Hidden-Layer-1', #Logical name\n",
        "                                                          activation='relu'))    #activation function\n",
        "\n",
        "                            #Add a second hidden layer\n",
        "                            model.add(keras.layers.Dense(128,\n",
        "                                                          name='Hidden-Layer-2',\n",
        "                                                          activation='relu'))\n",
        "\n",
        "                            #Add an output layer with softmax activation\n",
        "                            model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                                                        name='Output-Layer',\n",
        "                                                        activation='softmax'))\n",
        "\n",
        "                            #Compile the model with loss & metrics\n",
        "                            model.compile(loss='categorical_crossentropy',\n",
        "                                          metrics=['accuracy'])\n",
        "\n",
        "                            #Print the model meta-data\n",
        "                            model.summary()\n",
        "\n",
        "\n",
        "                            for layer_count in range(1,6):\n",
        "                                \n",
        "                                #32 nodes in each layer\n",
        "                                #layer_list.append(32)\n",
        "                                \n",
        "                                model_config = base_model_config()\n",
        "                                X,Y = get_rca_data()\n",
        "                                \n",
        "                                model_config[\"HIDDEN_NODES\"] = layer_list\n",
        "                                model_name = \"Layers-\" + str(layer_count)\n",
        "                                history=create_and_run_model(model_config,X,Y,model_name)\n",
        "                                \n",
        "                                accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "                            \n",
        "           \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #------create model\n",
        "  #Create a sequencial model in Keras\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  #Add the first hidden layer\n",
        "  model.add(keras.layers.Dense(128,                    #Number of nodes\n",
        "                             input_shape=(4,),       #Number of input variables\n",
        "                              name='Hidden-Layer-1', #Logical name\n",
        "                              activation='relu'))    #activation function\n",
        "\n",
        "  #Add a second hidden layer\n",
        "  model.add(keras.layers.Dense(128,\n",
        "                              name='Hidden-Layer-2',\n",
        "                              activation='relu'))\n",
        "\n",
        "  #Add an output layer with softmax activation\n",
        "  model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax'))\n",
        "\n",
        "  #Compile the model with loss & metrics\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  #Print the model meta-data\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "  #------train the model\n",
        "\n",
        "  #Make it verbose so we can see the progress\n",
        "  VERBOSE=1\n",
        "\n",
        "  #Setup Hyper Parameters for training\n",
        "\n",
        "  #Set Batch size\n",
        "  BATCH_SIZE=16\n",
        "  #Set number of epochs\n",
        "  EPOCHS=10\n",
        "  #Set validation split. 20% of the training data will be used for validation\n",
        "  #after each epoch\n",
        "  VALIDATION_SPLIT=0.2\n",
        "\n",
        "  print(\"\\nTraining Progress:\\n------------------------------------\")\n",
        "\n",
        "  #Fit the model. This will perform the entire training cycle, including\n",
        "  #forward propagation, loss computation, backward propagation and gradient descent.\n",
        "  #Execute for the specified batch sizes and epoch\n",
        "  #Perform validation after each epoch \n",
        "  history=model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "  print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  #Plot accuracy of the model after each epoch.\n",
        "  pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
        "  plt.title(\"Accuracy improvements with Epoch\")\n",
        "  plt.show()\n",
        "\n",
        "  #Evaluate the model against the test dataset and print results\n",
        "  print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
        "  model.evaluate(X_test,Y_test)\n",
        "\n",
        "  #------Saving a model\n",
        "    \n",
        "  model.save(\"iris_save\")\n",
        "      \n",
        "  #Loading a Model \n",
        "  loaded_model = keras.models.load_model(\"iris_save\")\n",
        "\n",
        "  #Print Model Summary\n",
        "  loaded_model.summary()\n"
      ],
      "metadata": {
        "id": "eGOzEpfOaQu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9__fWLtIcun0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NudahUSVcuja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bb5fad2"
      },
      "source": [
        "### 4.3. Creating a Model\n",
        "\n",
        "Creating a model in Keras requires defining the following\n",
        "\n",
        "1. Number of hidden layers\n",
        "2. Number of nodes in each layer\n",
        "3. Activation functions\n",
        "4. Loss Function & Accuracy measurements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EJfE5T09I645"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4a0be90",
        "outputId": "7c3fe3fc-75ef-418b-be1a-0b36ae902cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
            "                                                                 \n",
            " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,539\n",
            "Trainable params: 17,539\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "#Number of classes in the target variable\n",
        "NB_CLASSES=3\n",
        "\n",
        "#Create a sequencial model in Keras\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Add the first hidden layer\n",
        "model.add(keras.layers.Dense(128,                    #Number of nodes\n",
        "                             input_shape=(4,),       #Number of input variables\n",
        "                              name='Hidden-Layer-1', #Logical name\n",
        "                              activation='relu'))    #activation function\n",
        "\n",
        "#Add a second hidden layer\n",
        "model.add(keras.layers.Dense(128,\n",
        "                              name='Hidden-Layer-2',\n",
        "                              activation='relu'))\n",
        "\n",
        "#Add an output layer with softmax activation\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax'))\n",
        "\n",
        "#Compile the model with loss & metrics\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Print the model meta-data\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95c6677e"
      },
      "source": [
        "### 4.4. Training and evaluating the Model\n",
        "\n",
        "Training the model involves defining various training models and then perform \n",
        "forward and back propagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55a9ddba",
        "outputId": "3979dd3c-e3ae-48ac-e057-5e977eac68ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Progress:\n",
            "------------------------------------\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 160ms/step - loss: 0.7753 - accuracy: 0.7500 - val_loss: 0.5343 - val_accuracy: 0.9259\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.5095 - accuracy: 0.8148 - val_loss: 0.3958 - val_accuracy: 0.8889\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4187 - accuracy: 0.8148 - val_loss: 0.3284 - val_accuracy: 0.8889\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3638 - accuracy: 0.8519 - val_loss: 0.2816 - val_accuracy: 0.9259\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.3299 - accuracy: 0.8704 - val_loss: 0.2525 - val_accuracy: 0.8889\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.2946 - accuracy: 0.8796 - val_loss: 0.2269 - val_accuracy: 0.9259\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.2738 - accuracy: 0.8889 - val_loss: 0.2069 - val_accuracy: 0.9259\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2518 - accuracy: 0.8981 - val_loss: 0.1891 - val_accuracy: 0.9259\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2290 - accuracy: 0.9167 - val_loss: 0.1764 - val_accuracy: 0.9259\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.2080 - accuracy: 0.9444 - val_loss: 0.1622 - val_accuracy: 0.9259\n",
            "\n",
            "Accuracy during Training :\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1882 - accuracy: 0.8667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18818838894367218, 0.8666666746139526]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Make it verbose so we can see the progress\n",
        "VERBOSE=1\n",
        "\n",
        "#Setup Hyper Parameters for training\n",
        "\n",
        "#Set Batch size\n",
        "BATCH_SIZE=16\n",
        "#Set number of epochs\n",
        "EPOCHS=10\n",
        "#Set validation split. 20% of the training data will be used for validation\n",
        "#after each epoch\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
        "\n",
        "#Fit the model. This will perform the entire training cycle, including\n",
        "#forward propagation, loss computation, backward propagation and gradient descent.\n",
        "#Execute for the specified batch sizes and epoch\n",
        "#Perform validation after each epoch \n",
        "history=model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot accuracy of the model after each epoch.\n",
        "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
        "plt.title(\"Accuracy improvements with Epoch\")\n",
        "plt.show()\n",
        "\n",
        "#Evaluate the model against the test dataset and print results\n",
        "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55efdff7"
      },
      "source": [
        "### 4.5. Saving and Loading Models\n",
        "\n",
        "The training and inference environments are usually separate. Models need to be saved after they are validated. They are then loaded into the inference environments for actual prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7434d7cb",
        "outputId": "962ddef1-64bb-499d-a76a-b3f4f406f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Hidden-Layer-1_input with unsupported characters which will be renamed to hidden_layer_1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: iris_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: iris_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
            "                                                                 \n",
            " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,539\n",
            "Trainable params: 17,539\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Saving a model\n",
        "    \n",
        "model.save(\"iris_save\")\n",
        "    \n",
        "#Loading a Model \n",
        "loaded_model = keras.models.load_model(\"iris_save\")\n",
        "\n",
        "#Print Model Summary\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d8yEtmSPcuaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qi_LdUaDdiHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.3,random_state=2) #0.3 is 30% reserved for test. Popular integer random seeds are 0 and 42."
      ],
      "metadata": {
        "id": "eJ2bq_JEVsGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regular linera regression model\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(train_X,train_y)\n"
      ],
      "metadata": {
        "id": "7kXzorCnVsDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwT1vuFqud-I",
        "outputId": "ed6faeb6-15db-4c22-d1e4-81a58a23770c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9286086986856662"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(train_X,train_y)\n",
        "\n",
        "#if the training value is high compare with the test this indicate is overfiting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eybYNqQTutEA",
        "outputId": "f8638b21-9df0-4d77-f869-27ad8c72d63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9295652965670188"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#L1 is lasso Add a absolute theta value in the error (MSE)\n",
        "\n",
        "from sklearn import linear_model\n",
        "\n",
        "lasso_reg = linear_model.Lasso(alpha=50, max_iter=100, tol=0.1) #alpha ini random 50\n",
        "lasso_reg.fit(train_X,train_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1z0OcDlvIUx",
        "outputId": "90bfd49b-860b-419a-a6ed-4f9a11be4f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=50, max_iter=100, tol=0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_reg.score(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TDMbzS3vIRq",
        "outputId": "0d7ba6e3-3a3a-4e1e-d829-dff21334bfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.02447755713979749"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_reg.score(train_X,train_y)\n",
        "# in this cases ins not effective beacuse is not over fitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkRyqrUkvIOx",
        "outputId": "6367b79f-0148-47d5-d010-a9a7b2fcfdd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge(alpha=50, max_iter=100, tol=0.1) #alpha ini random 50\n",
        "ridge_reg.fit(train_X,train_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJA-4_zxvILp",
        "outputId": "907b7baa-0902-4cbc-db3d-6cac5b8fc87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=50, max_iter=100, tol=0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_reg.score(test_X,test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4oJPrP3vIJD",
        "outputId": "9166c21b-4cfd-4358-d5dd-6e82a52c376b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9099374641894389"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_reg.score(train_X,train_y)\n",
        "# in this cases is effective reducing score beacuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyVjtU1NvIGc",
        "outputId": "7d9ccd89-802f-4de8-919b-1041e9191368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.894234096271269"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QcmRmt8fdiDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dYJTf_XJdiA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j7PFKJmxdh9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AU1O3sdYcuPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HIDDEN_NODES\n",
        "\n",
        "accuracy_measures = {}\n",
        "layer_list =[]\n",
        "\n",
        "\n",
        "for layer_count in range(1,6):\n",
        "    \n",
        "    #32 nodes in each layer\n",
        "    layer_list.append(32)\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_rca_data()\n",
        "    \n",
        "    model_config[\"HIDDEN_NODES\"] = layer_list\n",
        "    model_name = \"Layers-\" + str(layer_count)\n",
        "    history=create_and_run_model(model_config,X,Y,model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "#NODES\n",
        "accuracy_measures = {}\n",
        "\n",
        "for node_count in range(8,40,8):\n",
        "    \n",
        "    #have 2 hidden layers in the networks\n",
        "    layer_list =[]\n",
        "    for layer_count in range(2):\n",
        "        layer_list.append(node_count)\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"HIDDEN_NODES\"] = layer_list\n",
        "    model_name = \"Nodes-\" + str(node_count)\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "#Batch size \n",
        "accuracy_measures = {}\n",
        "\n",
        "for batch_size in range(16,128,16):\n",
        "    \n",
        "    #Load default configuration\n",
        "    model_config = base_model_config()\n",
        "    #Acquire and process input data\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    #set epoch to 20\n",
        "    model_config[\"EPOCHS\"]=20\n",
        "    #Set batch size to experiment value\n",
        "    model_config[\"BATCH_SIZE\"] = batch_size\n",
        "    model_name = \"Batch-Size-\" + str(batch_size)\n",
        "    history=create_and_run_model(model_config,X,Y,model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "#Epoch size create...\n",
        "accuracy_measures = {}\n",
        "\n",
        "for batch_size in range(16,128,16):\n",
        "    \n",
        "    #Load default configuration\n",
        "    model_config = base_model_config()\n",
        "    #Acquire and process input data\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    #set epoch to 20\n",
        "    model_config[\"EPOCHS\"]=20\n",
        "    #Set batch size to experiment value\n",
        "    model_config[\"BATCH_SIZE\"] = batch_size\n",
        "    model_name = \"Batch-Size-\" + str(batch_size)\n",
        "    history=create_and_run_model(model_config,X,Y,model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "#Weights Initialization\n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "initializer_list = ['random_normal','zeros','ones',\"random_uniform\"]\n",
        "for initializer in initializer_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"WEIGHTS_INITIALIZER\"] = initializer\n",
        "    model_name = \"Model-\" + initializer\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#activation function \n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "activation_list = ['relu','sigmoid','tanh']\n",
        "\n",
        "for activation in activation_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"HIDDEN_ACTIVATION\"] = activation\n",
        "    model_name = \"Model-\" + activation\n",
        "    history=create_and_run_model(model_config,X,Y,model_name)\n",
        "    \n",
        "    accuracy_measures[\"Model-\" + activation] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "#optimizer \n",
        "accuracy_measures = {}\n",
        "\n",
        "optimizer_list = ['sgd','rmsprop','adam','adagrad']\n",
        "for optimizer in optimizer_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_rca_data()\n",
        "    \n",
        "    model_config[\"OPTIMIZER\"] = optimizer\n",
        "    model_name = \"Optimizer-\" + optimizer\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "#Batch Normalization\n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "normalization_list = ['none','batch']\n",
        "for normalization in normalization_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"NORMALIZATION\"] = normalization\n",
        "    model_name=\"Normalization-\" + normalization\n",
        "    history=create_and_run_model(model_config,X,Y,model_name)\n",
        "    \n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Learning Rates\n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "learning_rate_list = [0.001, 0.005,0.01,0.1,0.5]\n",
        "for learning_rate in learning_rate_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"LEARNING_RATE\"] = learning_rate\n",
        "    model_name=\"Learning-Rate-\" + str(learning_rate)\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    #accuracy\n",
        "    accuracy_measures[model_name] = history.history[\"accuracy\"]\n",
        "\n",
        "\n",
        "# Regularization\n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "regularizer_list = ['l1','l2','l1_l2']\n",
        "for regularizer in regularizer_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"REGULARIZER\"] = regularizer\n",
        "    model_config[\"EPOCHS\"]=25\n",
        "    model_name = \"Regularizer-\" + regularizer\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    #Switch to validation accuracy\n",
        "    accuracy_measures[model_name] = history.history[\"val_accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "# Dropout\n",
        "\n",
        "accuracy_measures = {}\n",
        "\n",
        "dropout_list = [0.0, 0.1, 0.2, 0.5]\n",
        "for dropout in dropout_list:\n",
        "    \n",
        "    model_config = base_model_config()\n",
        "    X,Y = get_data()\n",
        "    \n",
        "    model_config[\"DROPOUT_RATE\"] = dropout\n",
        "    model_config[\"EPOCHS\"]=25\n",
        "    model_name=\"Dropout-\" + str(dropout)\n",
        "    history=create_and_run_model(model_config,X,Y, model_name)\n",
        "    \n",
        "    #Using validation accuracy\n",
        "    accuracy_measures[model_name] = history.history[\"val_accuracy\"]\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "bQHq6BK8RMed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "d064c60a-e372-4cd8-f39f-33e4ada96f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "******************************************************\n",
            "Model: \"Layers-1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense-Layer-0 (Dense)       (None, 32)                256       \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 355\n",
            "Trainable params: 355\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "******************************************************\n",
            "Model: \"Layers-2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense-Layer-0 (Dense)       (None, 32)                256       \n",
            "                                                                 \n",
            " Dense-Layer-1 (Dense)       (None, 32)                1056      \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,411\n",
            "Trainable params: 1,411\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-216-29620bba0a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HIDDEN_NODES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Layers-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_and_run_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0maccuracy_measures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-197-ace1c481c6c9>\u001b[0m in \u001b[0;36mcreate_and_run_model\u001b[0;34m(model_config, X, Y, model_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EPOCHS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VERBOSE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m           validation_data= (X_val, Y_val))\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1516\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}